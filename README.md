# RAG1-Mini

A production-quality Retrieval-Augmented Generation (RAG) pipeline designed for learning and experimentation. Process any document collection through an 8-stage pipeline to build a searchable knowledge base with AI-powered answers.

## Highlights

- **Full RAG Pipeline**: 8 stages from PDF extraction to answer generation
- **Section-Aware Chunking**: Intelligent text segmentation with overlap
- **Advanced Retrieval**: Hybrid search, query preprocessing, cross-encoder reranking
- **Clean Architecture**: Function-based design with fail-fast error handling

## Technologies

| Category | Tools |
|----------|-------|
| **Language** | Python 3.8+ |
| **Vector Database** | Weaviate (HNSW + BM25 hybrid) |
| **LLM API** | OpenRouter (GPT-4, Claude, embeddings) |
| **NLP** | spaCy (en_core_sci_sm), tiktoken |
| **PDF Processing** | Docling |
| **Data Validation** | Pydantic (structured LLM outputs) |
| **UI** | Streamlit |
| **Evaluation** | RAGAS framework |
| **Infrastructure** | Docker, Conda |

## Pipeline Overview

```
PDF Documents
     |
     v
+-----------------------+
|  Stage 1: Extract     |  Docling PDF extraction
+-----------------------+
     |
     v
+-----------------------+
|  Stage 2: Clean       |  Regex-based artifact removal
+-----------------------+
     |
     v
+-----------------------+
|  Stage 3: Segment     |  spaCy NLP sentence segmentation
+-----------------------+
     |
     v
+-----------------------+
|  Stage 4: Chunk       |  800-token chunks, 2-sentence overlap
+-----------------------+
     |
     v
+-----------------------+
|  Stage 5: Embed       |  OpenRouter API embeddings
+-----------------------+
     |
     v
+-----------------------+
|  Stage 6: Store       |  Weaviate vector database
+-----------------------+
     |
     v
+-----------------------+
|  Stage 7: Search UI   |  Streamlit interface
+-----------------------+
     |
     v
+-----------------------+
|  Stage 8: Evaluate    |  RAGAS quality metrics
+-----------------------+
```

## Quick Start

```bash
# Setup environment
conda activate rag1-mini

# Run pipeline stages
python -m src.stages.run_stage_1_extraction   # Extract PDFs
python -m src.stages.run_stage_2_processing   # Clean markdown
python -m src.stages.run_stage_3_segmentation # NLP segmentation
python -m src.stages.run_stage_4_chunking     # Create chunks
python -m src.stages.run_stage_5_embedding    # Generate embeddings
python -m src.stages.run_stage_6_weaviate     # Upload to Weaviate

# Launch search UI
docker compose up -d                          # Start Weaviate
streamlit run src/ui/app.py                   # Open http://localhost:8501

# Run evaluation
python -m src.stages.run_stage_7_evaluation   # RAGAS quality metrics
```

## Project Structure

The codebase is organized into two main phases for learners:

```
RAG1-Mini: A Teaching RAG Pipeline
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ“š CONTENT PREPARATION (Stages 1-3)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚ Extraction  â”‚ â†’  â”‚  Cleaning   â”‚ â†’  â”‚Segmentation â”‚
   â”‚ (PDFâ†’MD)    â”‚    â”‚ (Fix MD)    â”‚    â”‚ (Sentences) â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
ğŸ¤– RAG PIPELINE (Stages 4-8)
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  Chunking   â”‚ â†’  â”‚  Embedding  â”‚ â†’  â”‚  Indexing   â”‚
   â”‚ (Sections)  â”‚    â”‚ (Vectors)   â”‚    â”‚ (Weaviate)  â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚              RETRIEVAL (Stage 7)                    â”‚
   â”‚  Query â†’ Preprocess â†’ Search â†’ Rerank â†’ Generate   â”‚
   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Directory Layout

```
rag1-mini/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ content_preparation/         # Phase 1: Documents â†’ Text
â”‚   â”‚   â”œâ”€â”€ extraction/              # Stage 1: PDF â†’ Markdown
â”‚   â”‚   â”‚   â””â”€â”€ docling_parser.py
â”‚   â”‚   â”œâ”€â”€ cleaning/                # Stage 2: Clean Markdown
â”‚   â”‚   â”‚   â””â”€â”€ text_cleaner.py
â”‚   â”‚   â””â”€â”€ segmentation/            # Stage 3: Sentence splits
â”‚   â”‚       â””â”€â”€ nlp_segmenter.py
â”‚   â”‚
â”‚   â”œâ”€â”€ rag_pipeline/                # Phase 2: RAG System
â”‚   â”‚   â”œâ”€â”€ chunking/                # Stage 4: Text â†’ Chunks
â”‚   â”‚   â”‚   â””â”€â”€ section_chunker.py
â”‚   â”‚   â”œâ”€â”€ embedding/               # Stage 5: Chunks â†’ Vectors
â”‚   â”‚   â”‚   â””â”€â”€ embedder.py
â”‚   â”‚   â”œâ”€â”€ indexing/                # Stage 6: Vector DB
â”‚   â”‚   â”‚   â”œâ”€â”€ weaviate_client.py
â”‚   â”‚   â”‚   â””â”€â”€ weaviate_query.py
â”‚   â”‚   â”œâ”€â”€ retrieval/               # Stage 7: Query â†’ Chunks
â”‚   â”‚   â”‚   â”œâ”€â”€ preprocessing/       # Query transformation
â”‚   â”‚   â”‚   â”œâ”€â”€ reranking.py         # Cross-encoder
â”‚   â”‚   â”‚   â””â”€â”€ rrf.py               # Multi-query fusion
â”‚   â”‚   â””â”€â”€ generation/              # Stage 8: Chunks â†’ Answer
â”‚   â”‚       â””â”€â”€ answer_generator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                  # RAGAS framework
â”‚   â”‚   â””â”€â”€ ragas_evaluator.py
â”‚   â”œâ”€â”€ ui/                          # Streamlit app
â”‚   â”‚   â””â”€â”€ app.py
â”‚   â”œâ”€â”€ shared/                      # Common utilities
â”‚   â”‚   â”œâ”€â”€ openrouter_client.py     # Unified LLM API
â”‚   â”‚   â”œâ”€â”€ files.py
â”‚   â”‚   â””â”€â”€ tokens.py
â”‚   â”œâ”€â”€ stages/                      # Pipeline stage runners
â”‚   â”‚   â”œâ”€â”€ run_stage_1_extraction.py
â”‚   â”‚   â”œâ”€â”€ run_stage_2_processing.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ config.py                    # Central configuration
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                         # Original PDF documents
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ 01_raw_extraction/       # Stage 1 output
â”‚       â”œâ”€â”€ 02_manual_review/        # Manual review
â”‚       â”œâ”€â”€ 03_markdown_cleaning/    # Stage 2 output
â”‚       â”œâ”€â”€ 04_nlp_chunks/           # Stage 3 output
â”‚       â”œâ”€â”€ 05_final_chunks/         # Stage 4 output
â”‚       â””â”€â”€ 06_embeddings/           # Stage 5 output
â””â”€â”€ memory-bank/                     # Project documentation
```

## Technical Design

### Architecture Principles

- **Function-based**: Functions as primary interface; classes only for stateful components
- **Fail-fast**: Exceptions propagate immediately; no log-and-continue
- **Absolute imports**: Consistent `from src.module import ...` pattern
- **Centralized config**: All settings in `src/config.py`

### Chunking Strategy

- **Token limit**: 800 tokens per chunk (optimized for embedding models)
- **Overlap**: 2 sentences carried between consecutive chunks
- **Section-aware**: Respects document structure boundaries
- **Quality filtering**: Removes sentence fragments and artifacts

### Key Parameters

```python
MAX_CHUNK_TOKENS = 800      # Target chunk size
OVERLAP_SENTENCES = 2       # Context continuity
SPACY_MODEL = "en_core_sci_sm"  # Scientific NLP
```

## RAG Techniques Applied

This project implements advanced RAG patterns from recent research:

| Technique | Description | Paper/Source |
|-----------|-------------|--------------|
| **Hybrid Search** | BM25 keyword + vector semantic search | Weaviate docs |
| **Step-Back Prompting** | Abstracts questions to broader concepts (+27% on multi-hop) | [arXiv:2310.06117](https://arxiv.org/abs/2310.06117) |
| **Multi-Query + RRF** | Generates targeted queries, merges with Reciprocal Rank Fusion | [Query Decomposition](https://arxiv.org/html/2507.00355v1) |
| **Query Decomposition** | Breaks complex questions into sub-queries (+36.7% MRR@10) | [Haystack Blog](https://haystack.deepset.ai/blog/query-decomposition) |
| **Cross-Encoder Reranking** | Re-scores results with BERT (+20-35% precision) | sentence-transformers |
| **Structured LLM Outputs** | Pydantic + JSON Schema enforcement | OpenAI structured outputs |
| **Section-Aware Chunking** | Respects document boundaries with overlap | RAG best practices |
| **RAGAS Evaluation** | LLM-as-judge via LangChain wrapper (faithfulness, relevancy, context precision) | [RAGAS framework](https://docs.ragas.io/) |

## Requirements

- Python 3.8+
- Conda environment: `rag1-mini`
- Dependencies: docling, spacy, tiktoken, requests, weaviate-client, streamlit, ragas, langchain-openai
- OpenRouter API key (for embeddings)
- Docker (for Weaviate vector database)

## License

MIT
