{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c9ebf2-a753-468d-b3a5-1cb76ddc0f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/fliperbaker/miniconda3/envs/rag1-mini/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84d4f10a-38ea-4396-828f-5b6c0ac4c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42854987-6fb0-4783-b7fa-020a73914a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fliperbaker/miniconda3/envs/rag1-mini/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Updated imports to support OCR configuration\n",
    "from docling.datamodel.document import InputFormat\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import ConversionStatus\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b2fe2292-95ba-46f7-9a7a-4be1d6f7ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = Path.cwd()\n",
    "PROJECT_ROOT = notebook_dir.parent\n",
    "#filename = \"ch1_ch14_Brain_and_behavior\"\n",
    "filename = \"PRECLEAN_Brain_and_behavior_a_cognitive_neuroscience_perspective_David_Eagleman_Jonathan_Downar\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5847a40-6bd6-43fc-9b4f-8af583686e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook is in: /home/fliperbaker/projects/rag1/rag1-mini/notebooks\n",
      "Project root is: /home/fliperbaker/projects/rag1/rag1-mini\n"
     ]
    }
   ],
   "source": [
    "print(f\"Notebook is in: {notebook_dir}\")\n",
    "print(f\"Project root is: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abf1d9f7-588f-4e8d-a8cf-c7a3290fd26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the full path and then add the .pdf suffix\n",
    "source_file = (PROJECT_ROOT / \"data\" / \"raw\" / \"neuroscience\" / filename).with_suffix(\".pdf\")\n",
    "\n",
    "# Construct the full path and then add the .md suffix\n",
    "destination_file = (PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / filename).with_suffix(\".md\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74c36be-d907-4f24-840c-d59ddd4d004a",
   "metadata": {},
   "source": [
    "## conversion no_ocr no_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f85002e-14cd-441e-97b6-d4f0d9326341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define Pipeline Options\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_ocr = False           # <--- Force OCR OFF (Fast & clean for digital docs)\n",
    "pipeline_options.do_table_structure = False # Keep table recognition ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de813c95-4fa7-411e-8824-92af8985e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize Converter with specific PDF options\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7516cea-edd9-4190-8197-41e9baa1a9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-05 12:44:12,437 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-05 12:44:12,842 - INFO - Going to convert document batch...\n",
      "2025-12-05 12:44:12,843 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 1216607fb7e04989285a12764e030fc9\n",
      "2025-12-05 12:44:12,855 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-05 12:44:12,862 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-12-05 12:44:12,871 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-05 12:44:12,879 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-12-05 12:44:12,895 - INFO - Accelerator device: 'cpu'\n",
      "2025-12-05 12:44:13,544 - INFO - Processing document PRECLEAN_Brain_and_behavior_a_cognitive_neuroscience_perspective_David_Eagleman_Jonathan_Downar.pdf\n",
      "2025-12-05 12:55:08,333 - INFO - Finished converting document PRECLEAN_Brain_and_behavior_a_cognitive_neuroscience_perspective_David_Eagleman_Jonathan_Downar.pdf in 598.28 sec.\n"
     ]
    }
   ],
   "source": [
    "result = converter.convert(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9dc8a61b-35f6-4aa1-ad86-6a6ff8ae5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the internal DoclingDocument object\n",
    "doc = result.document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d786ec5-fa33-4d5a-851b-ad9ff66ed8a1",
   "metadata": {},
   "source": [
    "## save markdown and json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd9a4dfc-09f8-4e4d-a5a9-9908a29e7b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2449930"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination_file.write_text(result.document.export_to_markdown(), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "350ee2a2-4212-467b-b27c-03d664e63376",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_json = (PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / filename).with_suffix(\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4917757-7bb1-4f24-8688-e8db106c7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Option B: Save to a JSON file for easier inspection in a text editor\n",
    "doc.save_as_json(destination_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78790ae-6f97-40bb-a036-fca86efa03de",
   "metadata": {},
   "source": [
    "## possible labels of docling items\n",
    "https://github.com/docling-project/docling-core/blob/main/docling_core/types/doc/labels.py\n",
    "```\n",
    "class DocItemLabel(str, Enum):\n",
    "    \"\"\"DocItemLabel.\"\"\"\n",
    "\n",
    "    CAPTION = \"caption\"\n",
    "    CHART = \"chart\"\n",
    "    FOOTNOTE = \"footnote\"\n",
    "    FORMULA = \"formula\"\n",
    "    LIST_ITEM = \"list_item\"\n",
    "    PAGE_FOOTER = \"page_footer\"\n",
    "    PAGE_HEADER = \"page_header\"\n",
    "    PICTURE = \"picture\"\n",
    "    SECTION_HEADER = \"section_header\"\n",
    "    TABLE = \"table\"\n",
    "    TEXT = \"text\"\n",
    "    TITLE = \"title\"\n",
    "    DOCUMENT_INDEX = \"document_index\"\n",
    "    CODE = \"code\"\n",
    "    CHECKBOX_SELECTED = \"checkbox_selected\"\n",
    "    CHECKBOX_UNSELECTED = \"checkbox_unselected\"\n",
    "    FORM = \"form\"\n",
    "    KEY_VALUE_REGION = \"key_value_region\"\n",
    "    GRADING_SCALE = \"grading_scale\"  # for elements in forms, questionaires representing a grading scale\n",
    "    # e.g. [strongly disagree | ... | ... | strongly agree]\n",
    "    # e.g. ★★☆☆☆\n",
    "    HANDWRITTEN_TEXT = \"handwritten_text\"\n",
    "    EMPTY_VALUE = \"empty_value\"  # used for empty value fields in fillable forms\n",
    "\n",
    "    # Additional labels for markup-based formats (e.g. HTML, Word)\n",
    "    PARAGRAPH = \"paragraph\"\n",
    "    REFERENCE = \"reference\"```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b7ec1f-42de-4401-8e1c-623cba6d7c37",
   "metadata": {},
   "source": [
    "## delete unwanted items\n",
    "\n",
    "DocItemLabel.CAPTION, DocItemLabel.FOOTNOTE, \n",
    "                    DocItemLabel.PAGE_FOOTER, DocItemLabel.PAGE_HEADER, \n",
    "                    DocItemLabel.TABLE\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "630cfcb7-0f62-458f-87d4-f774592cf60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from docling.datamodel.document import DocItemLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44b36db0-ecd5-4b57-87bf-de4a1564417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Identify items to remove (e.g., remove all Captions and Footnotes)\n",
    "# We collect them in a list first to avoid modifying the tree while iterating\n",
    "items_to_remove = []\n",
    "labels_to_remove = {DocItemLabel.CAPTION, DocItemLabel.FOOTNOTE, \n",
    "                    DocItemLabel.PAGE_FOOTER, DocItemLabel.PAGE_HEADER, \n",
    "                    DocItemLabel.TABLE}\n",
    "\n",
    "for item, level in doc.iterate_items():\n",
    "    # Check if the item has a label and if it matches our target list\n",
    "    if hasattr(item, \"label\") and item.label in labels_to_remove:\n",
    "        items_to_remove.append(item)\n",
    "\n",
    "# 3. Delete the items from the document\n",
    "# This updates the document tree in-place\n",
    "doc.delete_items(node_items=items_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1655fa37-9d30-49b2-ac7e-fb6c0dc9b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_removeditems = filename + \"_removeditems\"\n",
    "destination_file_removeditems = (PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / filename_removeditems).with_suffix(\".md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "833b2929-1b82-49ed-84e7-2d5584ed750a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2302755"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Now 'doc' can be passed to your RAG pipeline (e.g., chunking or export)\n",
    "destination_file_removeditems.write_text(doc.export_to_markdown(), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8178c03f-889a-462c-9baa-2bbf4b2928a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_file_json_removeditems = (PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / filename_removeditems).with_suffix(\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c7172c4-e678-4270-b099-7b287aea120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.save_as_json(destination_file_json_removeditems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4827027d-4248-476e-bf04-cf2110e809e9",
   "metadata": {},
   "source": [
    "## delete pictures and its children\n",
    "removes picture elements that contain texts inside the picture. No OCR is done but small texts like (a) (b) digital text inside the picture makes the converter to create picture items (empty) that contains small texts. This is to remove that noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3feaa2b5-6154-4851-808e-5d63bcab3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Helper function to find all children recursively\n",
    "def get_all_descendants(item):\n",
    "    \"\"\"Recursively collect all children, grandchildren, etc.\"\"\"\n",
    "    descendants = []\n",
    "    # Check if the item has children\n",
    "    if hasattr(item, \"children\") and item.children:\n",
    "        for child in item.children:\n",
    "            descendants.append(child)\n",
    "            # Recursively get children of the child\n",
    "            descendants.extend(get_all_descendants(child))\n",
    "    return descendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "965d60fd-0f72-4bda-8d33-f159d4b60bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Identify items to remove\n",
    "items_to_remove = []   # Use a list instead of a set\n",
    "seen_ids = set()       # Track IDs to avoid duplicates\n",
    "\n",
    "for item, level in doc.iterate_items():\n",
    "    # Check if it is a Picture\n",
    "    if hasattr(item, \"label\") and item.label == DocItemLabel.PICTURE:\n",
    "        \n",
    "        # A. Add the Picture item itself (if not already added)\n",
    "        if id(item) not in seen_ids:\n",
    "            items_to_remove.append(item)\n",
    "            seen_ids.add(id(item))\n",
    "        \n",
    "        # B. Get all children (captions, texts inside)\n",
    "        children = get_all_descendants(item)\n",
    "        \n",
    "        for child in children:\n",
    "            if id(child) not in seen_ids:\n",
    "                items_to_remove.append(child)\n",
    "                seen_ids.add(id(child))\n",
    "\n",
    "# 4. Delete the items\n",
    "if items_to_remove:\n",
    "    print(f\"Removing {len(items_to_remove)} items...\")\n",
    "    doc.delete_items(node_items=items_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a9428d3-f924-413c-bfa8-f74035585753",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_removedpictures = filename + \"_removedpictures\"\n",
    "destination_file_json_removedpictures= (PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / filename_removedpictures).with_suffix(\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79cdb282-0e8e-48f0-879d-266bd52557de",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.save_as_json(destination_file_json_removedpictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5341cd90-e689-407d-9649-6b02502cdc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_file_removedpictures= (PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / filename_removedpictures).with_suffix(\".md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "451334d1-3ba7-4e41-93d9-31d4df5dcaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2302755"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination_file_removedpictures.write_text(doc.export_to_markdown(), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b12644f-22a9-4dfa-96ce-44d57afc53ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag1-mini",
   "language": "python",
   "name": "rag1-mini"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
