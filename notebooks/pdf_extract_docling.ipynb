{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84d4f10a-38ea-4396-828f-5b6c0ac4c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42854987-6fb0-4783-b7fa-020a73914a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fliperbaker/miniconda3/envs/rag1-mini/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Updated imports to support OCR configuration\n",
    "from docling.datamodel.document import InputFormat\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import ConversionStatus\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2fe2292-95ba-46f7-9a7a-4be1d6f7ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = Path.cwd()\n",
    "PROJECT_ROOT = notebook_dir.parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5847a40-6bd6-43fc-9b4f-8af583686e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook is in: /home/fliperbaker/projects/rag1/rag1-mini/notebooks\n",
      "Project root is: /home/fliperbaker/projects/rag1/rag1-mini\n"
     ]
    }
   ],
   "source": [
    "print(f\"Notebook is in: {notebook_dir}\")\n",
    "print(f\"Project root is: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abf1d9f7-588f-4e8d-a8cf-c7a3290fd26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file = PROJECT_ROOT / \"data\" / \"raw\" / \"neuroscience\" / \"PRECLEAN_Brain_and_behavior_a_cognitive_neuroscience_perspective_David_Eagleman_Jonathan_Downar.pdf\"\n",
    "destination_file = PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / \"PRECLEAN_Brain_and_behavior_a_cognitive_neuroscience_perspective_David_Eagleman_Jonathan_Downar.md\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74c36be-d907-4f24-840c-d59ddd4d004a",
   "metadata": {},
   "source": [
    "## conversion no_ocr no_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f85002e-14cd-441e-97b6-d4f0d9326341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define Pipeline Options\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_ocr = False           # <--- Force OCR OFF (Fast & clean for digital docs)\n",
    "pipeline_options.do_table_structure = False # Keep table recognition ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de813c95-4fa7-411e-8824-92af8985e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize Converter with specific PDF options\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7516cea-edd9-4190-8197-41e9baa1a9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-03 05:26:16,501 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
      "2025-12-03 05:26:16,783 - INFO - Going to convert document batch...\n",
      "2025-12-03 05:26:16,784 - INFO - Initializing pipeline for StandardPdfPipeline with options hash 1216607fb7e04989285a12764e030fc9\n",
      "2025-12-03 05:26:16,792 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-03 05:26:16,794 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
      "2025-12-03 05:26:16,800 - INFO - Loading plugin 'docling_defaults'\n",
      "2025-12-03 05:26:16,805 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
      "2025-12-03 05:26:16,812 - INFO - Accelerator device: 'cpu'\n",
      "2025-12-03 05:26:17,427 - INFO - Processing document PRECLEAN_Brain_and_behavior_a_cognitive_neuroscience_perspective_David_Eagleman_Jonathan_Downar.pdf\n",
      "2025-12-03 05:37:11,163 - INFO - Finished converting document PRECLEAN_Brain_and_behavior_a_cognitive_neuroscience_perspective_David_Eagleman_Jonathan_Downar.pdf in 654.66 sec.\n"
     ]
    }
   ],
   "source": [
    "result = converter.convert(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dc8a61b-35f6-4aa1-ad86-6a6ff8ae5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the internal DoclingDocument object\n",
    "doc = result.document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d786ec5-fa33-4d5a-851b-ad9ff66ed8a1",
   "metadata": {},
   "source": [
    "## save markdown and json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a4dfc-09f8-4e4d-a5a9-9908a29e7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_file.write_text(result.document.export_to_markdown(), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ee2a2-4212-467b-b27c-03d664e63376",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_json = PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / \"PRECLEAN_Brain_and_behavior.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4917757-7bb1-4f24-8688-e8db106c7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Option B: Save to a JSON file for easier inspection in a text editor\n",
    "doc.save_as_json(destination_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78790ae-6f97-40bb-a036-fca86efa03de",
   "metadata": {},
   "source": [
    "## possible labels of docling items\n",
    "https://github.com/docling-project/docling-core/blob/main/docling_core/types/doc/labels.py\n",
    "```\n",
    "class DocItemLabel(str, Enum):\n",
    "    \"\"\"DocItemLabel.\"\"\"\n",
    "\n",
    "    CAPTION = \"caption\"\n",
    "    CHART = \"chart\"\n",
    "    FOOTNOTE = \"footnote\"\n",
    "    FORMULA = \"formula\"\n",
    "    LIST_ITEM = \"list_item\"\n",
    "    PAGE_FOOTER = \"page_footer\"\n",
    "    PAGE_HEADER = \"page_header\"\n",
    "    PICTURE = \"picture\"\n",
    "    SECTION_HEADER = \"section_header\"\n",
    "    TABLE = \"table\"\n",
    "    TEXT = \"text\"\n",
    "    TITLE = \"title\"\n",
    "    DOCUMENT_INDEX = \"document_index\"\n",
    "    CODE = \"code\"\n",
    "    CHECKBOX_SELECTED = \"checkbox_selected\"\n",
    "    CHECKBOX_UNSELECTED = \"checkbox_unselected\"\n",
    "    FORM = \"form\"\n",
    "    KEY_VALUE_REGION = \"key_value_region\"\n",
    "    GRADING_SCALE = \"grading_scale\"  # for elements in forms, questionaires representing a grading scale\n",
    "    # e.g. [strongly disagree | ... | ... | strongly agree]\n",
    "    # e.g. ★★☆☆☆\n",
    "    HANDWRITTEN_TEXT = \"handwritten_text\"\n",
    "    EMPTY_VALUE = \"empty_value\"  # used for empty value fields in fillable forms\n",
    "\n",
    "    # Additional labels for markup-based formats (e.g. HTML, Word)\n",
    "    PARAGRAPH = \"paragraph\"\n",
    "    REFERENCE = \"reference\"```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b7ec1f-42de-4401-8e1c-623cba6d7c37",
   "metadata": {},
   "source": [
    "## delete unwanted items\n",
    "\n",
    "DocItemLabel.CAPTION, DocItemLabel.FOOTNOTE, \n",
    "                    DocItemLabel.PAGE_FOOTER, DocItemLabel.PAGE_HEADER, \n",
    "                    DocItemLabel.TABLE\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "630cfcb7-0f62-458f-87d4-f774592cf60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from docling.datamodel.document import DocItemLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44b36db0-ecd5-4b57-87bf-de4a1564417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Identify items to remove (e.g., remove all Captions and Footnotes)\n",
    "# We collect them in a list first to avoid modifying the tree while iterating\n",
    "items_to_remove = []\n",
    "labels_to_remove = {DocItemLabel.CAPTION, DocItemLabel.FOOTNOTE, \n",
    "                    DocItemLabel.PAGE_FOOTER, DocItemLabel.PAGE_HEADER, \n",
    "                    DocItemLabel.TABLE}\n",
    "\n",
    "for item, level in doc.iterate_items():\n",
    "    # Check if the item has a label and if it matches our target list\n",
    "    if hasattr(item, \"label\") and item.label in labels_to_remove:\n",
    "        items_to_remove.append(item)\n",
    "\n",
    "# 3. Delete the items from the document\n",
    "# This updates the document tree in-place\n",
    "doc.delete_items(node_items=items_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1655fa37-9d30-49b2-ac7e-fb6c0dc9b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_file_removeditems = PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / \"PRECLEAN_Brain_and_behavior_removeditems.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b2929-1b82-49ed-84e7-2d5584ed750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Now 'doc' can be passed to your RAG pipeline (e.g., chunking or export)\n",
    "destination_file_removeditems.write_text(doc.export_to_markdown(), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178c03f-889a-462c-9baa-2bbf4b2928a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_file_json_removeditems = PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / \"PRECLEAN_Brain_and_behavior_removeditems.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7172c4-e678-4270-b099-7b287aea120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.save_as_json(destination_file_json_removeditems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4827027d-4248-476e-bf04-cf2110e809e9",
   "metadata": {},
   "source": [
    "## delete pictures and its children\n",
    "removes picture elements that contain texts inside the picture. No OCR is done but small texts like (a) (b) digital text inside the picture makes the converter to create picture items (empty) that contains small texts. This is to remove that noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3feaa2b5-6154-4851-808e-5d63bcab3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Helper function to find all children recursively\n",
    "def get_all_descendants(item):\n",
    "    \"\"\"Recursively collect all children, grandchildren, etc.\"\"\"\n",
    "    descendants = []\n",
    "    # Check if the item has children\n",
    "    if hasattr(item, \"children\") and item.children:\n",
    "        for child in item.children:\n",
    "            descendants.append(child)\n",
    "            # Recursively get children of the child\n",
    "            descendants.extend(get_all_descendants(child))\n",
    "    return descendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "965d60fd-0f72-4bda-8d33-f159d4b60bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing 7404 items...\n"
     ]
    }
   ],
   "source": [
    "# 3. Identify items to remove\n",
    "items_to_remove = []   # Use a list instead of a set\n",
    "seen_ids = set()       # Track IDs to avoid duplicates\n",
    "\n",
    "for item, level in doc.iterate_items():\n",
    "    # Check if it is a Picture\n",
    "    if hasattr(item, \"label\") and item.label == DocItemLabel.PICTURE:\n",
    "        \n",
    "        # A. Add the Picture item itself (if not already added)\n",
    "        if id(item) not in seen_ids:\n",
    "            items_to_remove.append(item)\n",
    "            seen_ids.add(id(item))\n",
    "        \n",
    "        # B. Get all children (captions, texts inside)\n",
    "        children = get_all_descendants(item)\n",
    "        \n",
    "        for child in children:\n",
    "            if id(child) not in seen_ids:\n",
    "                items_to_remove.append(child)\n",
    "                seen_ids.add(id(child))\n",
    "\n",
    "# 4. Delete the items\n",
    "if items_to_remove:\n",
    "    print(f\"Removing {len(items_to_remove)} items...\")\n",
    "    doc.delete_items(node_items=items_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a9428d3-f924-413c-bfa8-f74035585753",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_file_json_removedpictures= PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / \"PRECLEAN_Brain_and_behavior_removedpictures.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79cdb282-0e8e-48f0-879d-266bd52557de",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.save_as_json(destination_file_json_removedpictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5341cd90-e689-407d-9649-6b02502cdc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_file_removedpictures= PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / \"PRECLEAN_Brain_and_behavior_removedpictures.md\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "451334d1-3ba7-4e41-93d9-31d4df5dcaab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2302755"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination_file_removedpictures.write_text(doc.export_to_markdown(), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb001a06-de34-4642-9d8f-c793a2ba304e",
   "metadata": {},
   "source": [
    "## scispacy to sementation, cleaning and named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40dd1ba9-60c3-4571-92ed-d0211fce42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1bb9a2ea-321c-43d3-9cb2-7ba1b15d759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION & SETUP ---\n",
    "# We define a data structure to keep our data clean as it moves through the pipeline\n",
    "@dataclass\n",
    "class ProcessedSentence:\n",
    "    text: str                     # The actual sentence string\n",
    "    entities: List[str]           # List of scientific entities found (e.g., \"Hippocampus\")\n",
    "    entity_labels: List[str]      # The types of entities (e.g., \"ORGAN\", \"CELL\")\n",
    "    source_metadata: Dict[str, Any] # The book info (Title, Author, Year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddc057be-ea62-4e0d-b0f3-3e203e04f143",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuroProcessor:\n",
    "    def __init__(self):\n",
    "        print(\"⏳ Loading SciSpacy models... (This happens only once)\")\n",
    "        \n",
    "        # MODEL 1: Structural/Linguistic Model\n",
    "        # Used for: Accurate Sentence Splitting\n",
    "        try:\n",
    "            self.nlp_seg = spacy.load(\"en_core_sci_md\")\n",
    "        except OSError:\n",
    "            raise OSError(\"Could not load 'en_core_sci_md'. Did you install it?\")\n",
    "\n",
    "        # MODEL 2: Specialized NER Model\n",
    "        # Used for: Extracting specific BioNLP entities\n",
    "        try:\n",
    "            self.nlp_ner = spacy.load(\"en_ner_bionlp13cg_md\")\n",
    "        except OSError:\n",
    "            raise OSError(\"Could not load 'en_ner_bionlp13cg_md'. Did you install it?\")\n",
    "            \n",
    "        print(\"✅ Models loaded successfully.\")\n",
    "\n",
    "    def process_text(self, raw_text: str, source_metadata: Dict[str, Any]) -> List[ProcessedSentence]:\n",
    "        \"\"\"\n",
    "        Takes raw text and global metadata, returns a list of enriched sentence objects.\n",
    "        \"\"\"\n",
    "        # 1. Basic Cleaning\n",
    "        # PDF text often has line breaks in the middle of sentences. We flatten them.\n",
    "        cleaned_text = re.sub(r'\\s+', ' ', raw_text).strip()\n",
    "        \n",
    "        print(f\"   -> Processing text length: {len(cleaned_text)} chars\")\n",
    "\n",
    "        # 2. Segmentation (Splitting into sentences)\n",
    "        # We use the 'sci' model because it handles abbreviations (e.g., 'Fig. 1', 'et al.') better\n",
    "        doc = self.nlp_seg(cleaned_text)\n",
    "        \n",
    "        # Filter: Ignore tiny sentences (< 10 chars) usually artifacts/page numbers\n",
    "        sentences = [sent.text.strip() for sent in doc.sents if len(sent.text.strip()) > 10]\n",
    "        print(f\"   -> Found {len(sentences)} valid sentences.\")\n",
    "\n",
    "        processed_output = []\n",
    "\n",
    "        # 3. Enrichment (NER + Stamping)\n",
    "        for sent in sentences:\n",
    "            # Run the Specialized NER model on just this sentence\n",
    "            ner_doc = self.nlp_ner(sent)\n",
    "            \n",
    "            # Extract unique entities\n",
    "            entities = list(set([ent.text for ent in ner_doc.ents]))\n",
    "            entity_types = list(set([ent.label_ for ent in ner_doc.ents]))\n",
    "            \n",
    "            # Create the object\n",
    "            processed_sentence = ProcessedSentence(\n",
    "                text=sent,\n",
    "                entities=entities,\n",
    "                entity_labels=entity_types,\n",
    "                source_metadata=source_metadata # <--- Metadata Injection\n",
    "            )\n",
    "            processed_output.append(processed_sentence)\n",
    "            \n",
    "        return processed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb1ff9f3-0114-41d5-bbde-79c001cc3879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Loading SciSpacy models... (This happens only once)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fliperbaker/miniconda3/envs/rag1-mini/lib/python3.11/site-packages/spacy/language.py:2195: FutureWarning: Possible set union at position 6328\n",
      "  deserializers[\"tokenizer\"] = lambda p: self.tokenizer.from_disk(  # type: ignore[union-attr]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Models loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# --- INITIALIZE PROCESSOR ---\n",
    "processor = NeuroProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6129b48-637f-4f64-90cc-51cb189c6dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag1-mini",
   "language": "python",
   "name": "rag1-mini"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
