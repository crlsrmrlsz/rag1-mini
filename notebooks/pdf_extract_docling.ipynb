{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27c9ebf2-a753-468d-b3a5-1cb76ddc0f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ccrs70/miniconda3/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d4f10a-38ea-4396-828f-5b6c0ac4c81c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42854987-6fb0-4783-b7fa-020a73914a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated imports to support OCR configuration\n",
    "from docling.datamodel.document import InputFormat\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import ConversionStatus\n",
    "from docling.datamodel.pipeline_options import PdfPipelineOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fe2292-95ba-46f7-9a7a-4be1d6f7ded4",
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_dir = Path.cwd()\n",
    "PROJECT_ROOT = notebook_dir.parent\n",
    "filename = \"ch1_ch14_Brain_and_behavior\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5847a40-6bd6-43fc-9b4f-8af583686e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Notebook is in: {notebook_dir}\")\n",
    "print(f\"Project root is: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf1d9f7-588f-4e8d-a8cf-c7a3290fd26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the full path and then add the .pdf suffix\n",
    "source_file = (PROJECT_ROOT / \"data\" / \"raw\" / \"neuroscience\" / filename).with_suffix(\".pdf\")\n",
    "\n",
    "# Construct the full path and then add the .md suffix\n",
    "destination_file = (PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / filename).with_suffix(\".md\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74c36be-d907-4f24-840c-d59ddd4d004a",
   "metadata": {},
   "source": [
    "## conversion no_ocr no_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f85002e-14cd-441e-97b6-d4f0d9326341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define Pipeline Options\n",
    "pipeline_options = PdfPipelineOptions()\n",
    "pipeline_options.do_ocr = False           # <--- Force OCR OFF (Fast & clean for digital docs)\n",
    "pipeline_options.do_table_structure = False # Keep table recognition ON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de813c95-4fa7-411e-8824-92af8985e41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize Converter with specific PDF options\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(pipeline_options=pipeline_options)\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7516cea-edd9-4190-8197-41e9baa1a9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = converter.convert(source_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc8a61b-35f6-4aa1-ad86-6a6ff8ae5307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the internal DoclingDocument object\n",
    "doc = result.document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d786ec5-fa33-4d5a-851b-ad9ff66ed8a1",
   "metadata": {},
   "source": [
    "## save markdown and json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9a4dfc-09f8-4e4d-a5a9-9908a29e7b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_file.write_text(result.document.export_to_markdown(), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350ee2a2-4212-467b-b27c-03d664e63376",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_json = (PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / filename).with_suffix(\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4917757-7bb1-4f24-8688-e8db106c7b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Option B: Save to a JSON file for easier inspection in a text editor\n",
    "doc.save_as_json(destination_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78790ae-6f97-40bb-a036-fca86efa03de",
   "metadata": {},
   "source": [
    "## possible labels of docling items\n",
    "https://github.com/docling-project/docling-core/blob/main/docling_core/types/doc/labels.py\n",
    "```\n",
    "class DocItemLabel(str, Enum):\n",
    "    \"\"\"DocItemLabel.\"\"\"\n",
    "\n",
    "    CAPTION = \"caption\"\n",
    "    CHART = \"chart\"\n",
    "    FOOTNOTE = \"footnote\"\n",
    "    FORMULA = \"formula\"\n",
    "    LIST_ITEM = \"list_item\"\n",
    "    PAGE_FOOTER = \"page_footer\"\n",
    "    PAGE_HEADER = \"page_header\"\n",
    "    PICTURE = \"picture\"\n",
    "    SECTION_HEADER = \"section_header\"\n",
    "    TABLE = \"table\"\n",
    "    TEXT = \"text\"\n",
    "    TITLE = \"title\"\n",
    "    DOCUMENT_INDEX = \"document_index\"\n",
    "    CODE = \"code\"\n",
    "    CHECKBOX_SELECTED = \"checkbox_selected\"\n",
    "    CHECKBOX_UNSELECTED = \"checkbox_unselected\"\n",
    "    FORM = \"form\"\n",
    "    KEY_VALUE_REGION = \"key_value_region\"\n",
    "    GRADING_SCALE = \"grading_scale\"  # for elements in forms, questionaires representing a grading scale\n",
    "    # e.g. [strongly disagree | ... | ... | strongly agree]\n",
    "    # e.g. â˜…â˜…â˜†â˜†â˜†\n",
    "    HANDWRITTEN_TEXT = \"handwritten_text\"\n",
    "    EMPTY_VALUE = \"empty_value\"  # used for empty value fields in fillable forms\n",
    "\n",
    "    # Additional labels for markup-based formats (e.g. HTML, Word)\n",
    "    PARAGRAPH = \"paragraph\"\n",
    "    REFERENCE = \"reference\"```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b7ec1f-42de-4401-8e1c-623cba6d7c37",
   "metadata": {},
   "source": [
    "## delete unwanted items\n",
    "\n",
    "DocItemLabel.CAPTION, DocItemLabel.FOOTNOTE, \n",
    "                    DocItemLabel.PAGE_FOOTER, DocItemLabel.PAGE_HEADER, \n",
    "                    DocItemLabel.TABLE\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630cfcb7-0f62-458f-87d4-f774592cf60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.document_converter import DocumentConverter\n",
    "from docling.datamodel.document import DocItemLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b36db0-ecd5-4b57-87bf-de4a1564417c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Identify items to remove (e.g., remove all Captions and Footnotes)\n",
    "# We collect them in a list first to avoid modifying the tree while iterating\n",
    "items_to_remove = []\n",
    "labels_to_remove = {DocItemLabel.CAPTION, DocItemLabel.FOOTNOTE, \n",
    "                    DocItemLabel.PAGE_FOOTER, DocItemLabel.PAGE_HEADER, \n",
    "                    DocItemLabel.TABLE}\n",
    "\n",
    "for item, level in doc.iterate_items():\n",
    "    # Check if the item has a label and if it matches our target list\n",
    "    if hasattr(item, \"label\") and item.label in labels_to_remove:\n",
    "        items_to_remove.append(item)\n",
    "\n",
    "# 3. Delete the items from the document\n",
    "# This updates the document tree in-place\n",
    "doc.delete_items(node_items=items_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1655fa37-9d30-49b2-ac7e-fb6c0dc9b867",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_removeditems = filename + \"_removeditems\"\n",
    "destination_file_removeditems = (PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / filename_removeditems).with_suffix(\".md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833b2929-1b82-49ed-84e7-2d5584ed750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Now 'doc' can be passed to your RAG pipeline (e.g., chunking or export)\n",
    "destination_file_removeditems.write_text(doc.export_to_markdown(), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8178c03f-889a-462c-9baa-2bbf4b2928a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_file_json_removeditems = (PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / filename_removeditems).with_suffix(\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7172c4-e678-4270-b099-7b287aea120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.save_as_json(destination_file_json_removeditems)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4827027d-4248-476e-bf04-cf2110e809e9",
   "metadata": {},
   "source": [
    "## delete pictures and its children\n",
    "removes picture elements that contain texts inside the picture. No OCR is done but small texts like (a) (b) digital text inside the picture makes the converter to create picture items (empty) that contains small texts. This is to remove that noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3feaa2b5-6154-4851-808e-5d63bcab3c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Helper function to find all children recursively\n",
    "def get_all_descendants(item):\n",
    "    \"\"\"Recursively collect all children, grandchildren, etc.\"\"\"\n",
    "    descendants = []\n",
    "    # Check if the item has children\n",
    "    if hasattr(item, \"children\") and item.children:\n",
    "        for child in item.children:\n",
    "            descendants.append(child)\n",
    "            # Recursively get children of the child\n",
    "            descendants.extend(get_all_descendants(child))\n",
    "    return descendants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d60fd-0f72-4bda-8d33-f159d4b60bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Identify items to remove\n",
    "items_to_remove = []   # Use a list instead of a set\n",
    "seen_ids = set()       # Track IDs to avoid duplicates\n",
    "\n",
    "for item, level in doc.iterate_items():\n",
    "    # Check if it is a Picture\n",
    "    if hasattr(item, \"label\") and item.label == DocItemLabel.PICTURE:\n",
    "        \n",
    "        # A. Add the Picture item itself (if not already added)\n",
    "        if id(item) not in seen_ids:\n",
    "            items_to_remove.append(item)\n",
    "            seen_ids.add(id(item))\n",
    "        \n",
    "        # B. Get all children (captions, texts inside)\n",
    "        children = get_all_descendants(item)\n",
    "        \n",
    "        for child in children:\n",
    "            if id(child) not in seen_ids:\n",
    "                items_to_remove.append(child)\n",
    "                seen_ids.add(id(child))\n",
    "\n",
    "# 4. Delete the items\n",
    "if items_to_remove:\n",
    "    print(f\"Removing {len(items_to_remove)} items...\")\n",
    "    doc.delete_items(node_items=items_to_remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9428d3-f924-413c-bfa8-f74035585753",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_removedpictures = filename + \"_removedpictures\"\n",
    "destination_file_json_removedpictures= (PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / filename_removedpictures).with_suffix(\".json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cdb282-0e8e-48f0-879d-266bd52557de",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.save_as_json(destination_file_json_removedpictures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5341cd90-e689-407d-9649-6b02502cdc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_file_removedpictures= (PROJECT_ROOT / \"data\" / \"processed\" / \"neuroscience\" / filename_removedpictures).with_suffix(\".md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451334d1-3ba7-4e41-93d9-31d4df5dcaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_file_removedpictures.write_text(doc.export_to_markdown(), encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb001a06-de34-4642-9d8f-c793a2ba304e",
   "metadata": {},
   "source": [
    "## scispacy to sementation, cleaning and named entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd1ba9-60c3-4571-92ed-d0211fce42f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9a2ea-321c-43d3-9cb2-7ba1b15d759e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. DATA STRUCTURES ---\n",
    "@dataclass\n",
    "class ProcessedSentence:\n",
    "    \"\"\"\n",
    "    Standardizes the output for every sentence.\n",
    "    This is what we will pass to the Chunking Phase.\n",
    "    \"\"\"\n",
    "    id: int                         # Sequence number (useful for ordering)\n",
    "    text: str                       # The clean sentence content\n",
    "    entities: List[str]             # List of extracted entities (e.g., 'Dopamine')\n",
    "    entity_labels: List[str]        # List of entity types (e.g., 'SIMPLE_CHEMICAL')\n",
    "    source_metadata: Dict[str, Any] # Grounding info (Book Title, Author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc057be-ea62-4e0d-b0f3-3e203e04f143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. THE PROCESSOR CLASS ---\n",
    "class NeuroProcessor:\n",
    "    def __init__(self):\n",
    "        print(\"â³ Loading SciSpacy models...\")\n",
    "        \n",
    "        # MODEL 1: Structural/Linguistic Model (en_core_sci_md)\n",
    "        # Why: This model is trained on biomedical text, so it knows that \"Fig. 1.2\"\n",
    "        # is not the end of a sentence. We use this ONLY for splitting sentences.\n",
    "        try:\n",
    "            self.nlp_seg = spacy.load(\"en_core_sci_md\")\n",
    "            # We disable NER here to save compute, we only want the parser for sentences\n",
    "            self.nlp_seg.disable_pipes([\"ner\"]) \n",
    "        except OSError:\n",
    "            raise OSError(\"Error: Could not load 'en_core_sci_md'. Please install it.\")\n",
    "\n",
    "        # MODEL 2: Specialized NER Model (en_ner_bionlp13cg_md)\n",
    "        # Why: This provides specific granular tags like ORGAN, CELL, TISSUE, \n",
    "        # rather than the generic tags found in the core model.\n",
    "        try:\n",
    "            self.nlp_ner = spacy.load(\"en_ner_bionlp13cg_md\")\n",
    "        except OSError:\n",
    "            raise OSError(\"Error: Could not load 'en_ner_bionlp13cg_md'. Please install it.\")\n",
    "            \n",
    "        print(\"âœ… Models loaded. Ready to process.\")\n",
    "\n",
    "    def process_text(self, markdown_text: str, metadata: Dict[str, Any]) -> List[ProcessedSentence]:\n",
    "        \"\"\"\n",
    "        Input: Clean Markdown string + Book Metadata.\n",
    "        Output: List of ProcessedSentence objects.\n",
    "        \"\"\"\n",
    "        # A. Cleanup: Collapse multiple spaces/newlines into single spaces\n",
    "        # This prevents the sentence splitter from getting confused by PDF line breaks\n",
    "        clean_text = \" \".join(markdown_text.split())\n",
    "        \n",
    "        # B. Segmentation (Model 1)\n",
    "        doc = self.nlp_seg(clean_text)\n",
    "        \n",
    "        # Filter out extremely short artifacts (like page numbers \"14\", or headers \"##\")\n",
    "        raw_sentences = [sent.text.strip() for sent in doc.sents if len(sent.text.strip()) > 10]\n",
    "        \n",
    "        processed_output = []\n",
    "\n",
    "        # C. Enrichment (Model 2)\n",
    "        print(f\"   -> Processing {len(raw_sentences)} sentences for entities...\")\n",
    "        \n",
    "        for i, sent_text in enumerate(raw_sentences):\n",
    "            # Run NER on the individual sentence\n",
    "            ner_doc = self.nlp_ner(sent_text)\n",
    "            \n",
    "            # Extract distinct entities and labels\n",
    "            # We use set() to remove duplicates (e.g., if 'neuron' appears twice in one sentence)\n",
    "            entities = list(set([ent.text for ent in ner_doc.ents]))\n",
    "            entity_labels = list(set([ent.label_ for ent in ner_doc.ents]))\n",
    "            \n",
    "            # Create the object\n",
    "            p_sent = ProcessedSentence(\n",
    "                id=i,\n",
    "                text=sent_text,\n",
    "                entities=entities,\n",
    "                entity_labels=entity_labels,\n",
    "                source_metadata=metadata\n",
    "            )\n",
    "            processed_output.append(p_sent)\n",
    "            \n",
    "        return processed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1ff9f3-0114-41d5-bbde-79c001cc3879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. HELPER FOR VISUALIZATION ---\n",
    "def visualize_results(processed_data: List[ProcessedSentence], num_samples: int = 3):\n",
    "    \"\"\"\n",
    "    Prints a clean JSON view of the first few sentences.\n",
    "    \"\"\"\n",
    "    # Convert dataclasses to dicts for JSON serialization\n",
    "    preview_data = [asdict(sent) for sent in processed_data[:num_samples]]\n",
    "    \n",
    "    print(\"\\nðŸ”Ž VISUAL INSPECTION (JSON PREVIEW):\")\n",
    "    print(json.dumps(preview_data, indent=2))\n",
    "    print(f\"\\n... (Total {len(processed_data)} sentences processed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6129b48-637f-4f64-90cc-51cb189c6dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. SETUP: Define your Metadata\n",
    "book_info = {\n",
    "    \"title\": \"Brain and Behavior\",\n",
    "    \"author\": \"Eagleman\",\n",
    "    \"chapter\": \"Chapter 1: Neural Foundations\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a561c8-fe89-47bf-b819-a16b9eef4b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. INPUT: Your Clean Markdown (Simulated here, replace with your 'clean_text' variable)\n",
    "markdown_input = destination_file_removedpictures\n",
    "\n",
    "# 3. RUN THE PIPELINE\n",
    "processor = NeuroProcessor()\n",
    "final_sentences = processor.process_text(markdown_input, book_info)\n",
    "\n",
    "# 4. VISUALIZE\n",
    "visualize_results(final_sentences, num_samples=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cc1d95-d075-47eb-a4cb-fc3e46cfe182",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (rag1-mini)",
   "language": "python",
   "name": "rag1-mini"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
